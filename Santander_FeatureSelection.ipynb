{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = 'input_data'\n",
    "train_df = pd.read_csv(os.path.join(data_dir, 'train.csv'), index_col='ID')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manual Feature Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Examing correlation between features and the target using a Spearman coefficient. Spearman's rank-order was chosen because of the extreme range of values in the target data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(os.path.join(data_dir, 'correlation_matrix.csv')):\n",
    "    correlation_matrix = pd.read_csv(os.path.join(data_dir, 'correlation_matrix.csv'), header=None, index_col=0, squeeze=True)\n",
    "else:\n",
    "    correlation_matrix = train_df.corr(method='spearman')['target'][1:]\n",
    "    correlation_matrix.to_csv(os.path.join(data_dir, 'correlation_matrix.csv'), header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spearman_threshold = .1\n",
    "correlated_features = correlation_matrix[abs(correlation_matrix) > spearman_threshold].sort_values(ascending=False)\n",
    "train_df_reduced = pd.concat([train_df.target, train_df[list(correlated_features.index)]], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Features have been reduced to only those with an absolute Spearman correlation value of over .1. Now, examining correlation of features with one another, and removing those that have a high Spearman correlation to one another."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_matrix = train_df_reduced.iloc[:, 1:].corr(method='spearman').abs()\n",
    "plt.figure(figsize=(10,10))\n",
    "sns.heatmap(feature_matrix, cmap='Reds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removing correlated features\n",
    "columns = np.full((feature_matrix.shape[0],), True, dtype=bool)\n",
    "\n",
    "for i in range(feature_matrix.shape[0]):\n",
    "    for j in range(i+1, feature_matrix.shape[0]):\n",
    "        if feature_matrix.iloc[i,j] >= 0.7:\n",
    "            if columns[j]:\n",
    "                columns[j] = False\n",
    "                \n",
    "selected_columns = train_df_reduced.iloc[:, 1:].columns[columns]\n",
    "train_df_reduced = pd.concat((train_df_reduced['target'], train_df_reduced[selected_columns]), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Features have been further reduced based on their Spearman correlation to one another. Now applying transforms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature and Target Data Transformations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on results in EDA, i opt to normalize the target using a Box-Cox method, and the features using a log transform (with zeros retained)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_method = 'log'\n",
    "\n",
    "def train_transform(df, method=None):\n",
    "    transformer = None\n",
    "    df['target'] = stats.boxcox(df['target'])[0]\n",
    "    if method == 'log':\n",
    "        log_vals = np.log(df.iloc[:, 1:].mask(df <=0)).fillna(0).values\n",
    "        df.iloc[:, 1:] = log_vals\n",
    "        return df, transformer\n",
    "    elif method == 'yeo-johnson':\n",
    "        transformer = preprocessing.PowerTransformer(method='yeo-johnson', standardize=True)\n",
    "        transformer.fit(df.iloc[:, 1:].values)\n",
    "        yeo_vals = transformer.transform(df.iloc[:, 1:].values)\n",
    "        df.iloc[:, 1:] = yeo_vals\n",
    "        return df, transformer\n",
    "    else:\n",
    "        return df, transformer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_reduced, transformer = train_transform(train_df_reduced, transform_method)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Saving to local drive\n",
    "train_df_reduced.to_csv(os.path.join(data_dir, 'train_reduced.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will apply the same steps to the test dataset here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Specifying columns to be used, then reading in reduced dataset\n",
    "cols_to_use = list(train_df_reduced.reset_index().drop('target', axis=1).columns)\n",
    "chunksize = 5000\n",
    "\n",
    "file_reader = pd.read_csv(os.path.join(data_dir, 'test.csv'), index_col='ID', chunksize=chunksize, usecols=cols_to_use)\n",
    "test_df_reduce = pd.concat(file_reader, ignore_index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Transforming test dataset, applying same method as that to training data\n",
    "\n",
    "def test_transform(df, method=None):\n",
    "    if method == 'log':\n",
    "        log_vals = np.log(df.iloc[:, 1:].mask(df <=0)).fillna(0).values\n",
    "        df.iloc[:, 1:] = log_vals\n",
    "        return df\n",
    "    elif method == 'yeo-johnson':\n",
    "        global transformer\n",
    "        yeo_vals = transformer.transform(df.values)\n",
    "        df.iloc[:, :] = yeo_vals\n",
    "        return df\n",
    "    else:\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_transform(test_df_reduce, method=transform_method)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving to local drive\n",
    "test_df_reduce.to_csv(os.path.join(data_dir, 'test_reduced.csv'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
