{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import pickle\n",
    "import datetime\n",
    "from scipy import stats, special\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import model_selection\n",
    "from sklearn.linear_model import Ridge, Lasso, SGDRegressor\n",
    "from sklearn.metrics import mean_squared_log_error\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, AdaBoostRegressor\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = 'input_data'\n",
    "transform = 'pca'\n",
    "model_dir = 'models'\n",
    "seed=0\n",
    "scoring='neg_mean_squared_error'\n",
    "time = datetime.datetime.now().strftime(\"%D\").replace('/', '-')\n",
    "\n",
    "if not os.path.exists(model_dir):\n",
    "    os.makedirs(model_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_file(transform=transform):\n",
    "    files_dict = {'sparse' : 'train_sparse_pca.csv', 'pca' : 'train_pca.csv', 'reduction' : 'train_reduced.csv', None : 'train.csv'}\n",
    "    df = pd.read_csv(os.path.join(data_dir, files_dict[transform]))\n",
    "    X = df.iloc[:, 1:].values\n",
    "    y = df.iloc[:, 0].values\n",
    "    X_train, X_validate, y_train, y_validate = model_selection.train_test_split(X, y, random_state=seed)\n",
    "    return X_train, X_validate, y_train, y_validate "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading and splitting transformed data\n",
    "X_train, X_validate, y_train, y_validate = get_train_file()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial Model Evaluation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = []\n",
    "models.append(('RCV', Ridge()))\n",
    "models.append(('SVM', SVR()))\n",
    "models.append(('RFR', RandomForestRegressor()))\n",
    "models.append(('GBM', AdaBoostRegressor()))\n",
    "models.append(('GBR', GradientBoostingRegressor()))\n",
    "models.append(('SGD', SGDRegressor()))\n",
    "models.append(('LSO', Lasso()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "names = []\n",
    "for name, model in models:\n",
    "    kfold = model_selection.KFold(n_splits=10, random_state=seed, shuffle=True)\n",
    "    cv_results = model_selection.cross_val_score(model, X_train, y_train, cv=kfold, scoring=scoring)\n",
    "    results.append(cv_results)\n",
    "    names.append(name)\n",
    "    msg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n",
    "    print(msg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random forest regression appears to perform the best"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selected Model Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like a baseline gradient boosted regression and random forest regression performed the best on the training data. I will focus on tuning the hyperparamters of these algorithms further using GridsearchCV. Lastly, i will explore the use of an XGBoost algorithm using SageMaker."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiating regressor and parameter search\n",
    "RFRegressor = RandomForestRegressor()\n",
    "grid_values_rfr = {'n_estimators' : [1, 10, 50, 100], 'max_depth' : [1, 3, 5, 10], 'min_samples_split' : [2, 3, 5]}\n",
    "RFRegressor_CV = model_selection.GridSearchCV(RFRegressor, param_grid = grid_values_rfr, scoring=scoring)\n",
    "RFRegressor_CV.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Making and evaluating predictions\n",
    "RFR_predicted = RFRegressor_CV.predict(X_validate)\n",
    "RFR_predicted = special.inv_boxcox(RFR_predicted.reshape(-1, 1), stats.boxcox(pd.read_csv(os.path.join(data_dir, 'train.csv'), usecols=['target', 'ID'], index_col='ID')['target'])[1])\n",
    "RFR_predicted = [x[0] for x in RFR_predicted]\n",
    "y_validate_inv = special.inv_boxcox(y_validate, stats.boxcox(pd.read_csv(os.path.join(data_dir, 'train.csv'), usecols=['target', 'ID'], index_col='ID')['target'])[1])\n",
    "np.sqrt(mean_squared_log_error(y_validate_inv, RFR_predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plotting results\n",
    "fig, (ax1, ax2) = plt.subplots(nrows=1, ncols=2, figsize=(20, 5)) \n",
    "ax1.scatter(y_validate_inv, RFR_predicted)\n",
    "ax1.set_title('Predicted Versus Actual Plot', fontsize=16)\n",
    "ax1.set_xlabel('y True', fontsize=12)\n",
    "ax1.set_ylabel('y Predicted', fontsize=12)\n",
    "ax2.scatter(range(len(RFR_predicted)), np.sort(RFR_predicted))\n",
    "ax2.set_title('Prediction Distribution', fontsize=16)\n",
    "ax2.set_xlabel('Index Number', fontsize=12)\n",
    "ax2.set_ylabel('Predicted Value', fontsize=12)\n",
    "fig.suptitle('Random Forest Model Results with {} Transform'.format(transform), fontsize=20, y=1.02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving random forest model data to model directory\n",
    "filename = 'RFR-model-{}-{}'.format(transform, time)\n",
    "pickle.dump(RFRegressor_CV, open(os.path.join(model_dir, filename), 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next i will construct an XGBoost regressor using the Sagemaker API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "sagemaker_session = sagemaker.Session()\n",
    "bucket = sagemaker_session.default_bucket()\n",
    "role = sagemaker.get_execution_role()\n",
    "model_prefix = 'santander_project/XGBoost'\n",
    "data_prefix = 'santander_project/data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'s3_input' class will be renamed to 'TrainingInput' in SageMaker Python SDK v2.\n",
      "'s3_input' class will be renamed to 'TrainingInput' in SageMaker Python SDK v2.\n"
     ]
    }
   ],
   "source": [
    "pd.concat([pd.DataFrame(y_validate), pd.DataFrame(X_validate)], axis=1).to_csv(os.path.join(data_dir, 'model_validation.csv'), header=False, index=False)\n",
    "pd.concat([pd.DataFrame(y_train), pd.DataFrame(X_train)], axis=1).to_csv(os.path.join(data_dir, 'model_train.csv'), header=False, index=False)\n",
    "\n",
    "val_location = sagemaker_session.upload_data(os.path.join(data_dir, 'model_validation.csv'), bucket=bucket, key_prefix=model_prefix)\n",
    "train_location = sagemaker_session.upload_data(os.path.join(data_dir, 'model_train.csv'), bucket=bucket, key_prefix=model_prefix)\n",
    "\n",
    "s3_input_train = sagemaker.s3_input(s3_data=train_location, content_type='csv')\n",
    "s3_input_validation = sagemaker.s3_input(s3_data=val_location, content_type='csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'get_image_uri' method will be deprecated in favor of 'ImageURIProvider' class in SageMaker Python SDK v2.\n",
      "There is a more up to date SageMaker XGBoost image. To use the newer image, please set 'repo_version'='1.0-1'. For example:\n",
      "\tget_image_uri(region, 'xgboost', '1.0-1').\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.amazon.amazon_estimator import get_image_uri\n",
    "\n",
    "container = get_image_uri(sagemaker_session.boto_region_name, 'xgboost')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parameter image_name will be renamed to image_uri in SageMaker Python SDK v2.\n"
     ]
    }
   ],
   "source": [
    "xgb_base = sagemaker.estimator.Estimator(container, \n",
    "                                    role,                                    \n",
    "                                    train_instance_count=1,                  \n",
    "                                    train_instance_type='ml.m4.xlarge',      \n",
    "                                    output_path='s3://{}/{}/output'.format(bucket, model_prefix),\n",
    "                                    sagemaker_session=sagemaker_session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.tuner import IntegerParameter, ContinuousParameter, HyperparameterTuner\n",
    "\n",
    "xgb_hyperparameter_tuner = HyperparameterTuner(estimator = xgb_base, \n",
    "                                               objective_metric_name = 'validation:rmse', \n",
    "                                               objective_type = 'Minimize', \n",
    "                                               max_jobs = 15, \n",
    "                                               max_parallel_jobs = 3,\n",
    "                                               hyperparameter_ranges = {\n",
    "                                                    'max_depth': IntegerParameter(3, 12),\n",
    "                                                    'eta'      : ContinuousParameter(0.05, 0.5),\n",
    "                                                    'min_child_weight': IntegerParameter(2, 8),\n",
    "                                                    'subsample': ContinuousParameter(0.5, 0.9),\n",
    "                                                    'gamma': ContinuousParameter(0, 10),\n",
    "                                                   'num_round' : IntegerParameter(1, 500)\n",
    "                                               })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..................................................................................................................................................................................................................!\n"
     ]
    }
   ],
   "source": [
    "xgb_hyperparameter_tuner.fit({'train': s3_input_train, 'validation': s3_input_validation})\n",
    "xgb_hyperparameter_tuner.wait()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parameter image_name will be renamed to image_uri in SageMaker Python SDK v2.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-07-27 22:53:30 Starting - Preparing the instances for training\n",
      "2020-07-27 22:53:30 Downloading - Downloading input data\n",
      "2020-07-27 22:53:30 Training - Training image download completed. Training in progress.\n",
      "2020-07-27 22:53:30 Uploading - Uploading generated training model\n",
      "2020-07-27 22:53:30 Completed - Training job completed\u001b[34mArguments: train\u001b[0m\n",
      "\u001b[34m[2020-07-27:22:53:18:INFO] Running standalone xgboost training.\u001b[0m\n",
      "\u001b[34m[2020-07-27:22:53:18:INFO] Setting up HPO optimized metric to be : rmse\u001b[0m\n",
      "\u001b[34m[2020-07-27:22:53:18:INFO] File size need to be processed in the node: 0.91mb. Available memory size in the node: 8491.84mb\u001b[0m\n",
      "\u001b[34m[2020-07-27:22:53:18:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34m[22:53:18] S3DistributionType set as FullyReplicated\u001b[0m\n",
      "\u001b[34m[22:53:18] 3343x10 matrix with 33430 entries loaded from /opt/ml/input/data/train?format=csv&label_column=0&delimiter=,\u001b[0m\n",
      "\u001b[34m[2020-07-27:22:53:18:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34m[22:53:18] S3DistributionType set as FullyReplicated\u001b[0m\n",
      "\u001b[34m[22:53:18] 1115x10 matrix with 11150 entries loaded from /opt/ml/input/data/validation?format=csv&label_column=0&delimiter=,\u001b[0m\n",
      "\u001b[34m[22:53:18] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 18 extra nodes, 0 pruned nodes, max_depth=4\u001b[0m\n",
      "\u001b[34m[0]#011train-rmse:26.4135#011validation-rmse:26.6132\u001b[0m\n",
      "\u001b[34m[22:53:18] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 74 extra nodes, 0 pruned nodes, max_depth=11\u001b[0m\n",
      "\u001b[34m[1]#011train-rmse:18.3151#011validation-rmse:18.5705\u001b[0m\n",
      "\u001b[34m[22:53:18] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 144 extra nodes, 0 pruned nodes, max_depth=11\u001b[0m\n",
      "\u001b[34m[2]#011train-rmse:13.3603#011validation-rmse:13.8477\u001b[0m\n",
      "\u001b[34m[22:53:18] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 204 extra nodes, 2 pruned nodes, max_depth=11\u001b[0m\n",
      "\u001b[34m[3]#011train-rmse:10.3435#011validation-rmse:10.9931\u001b[0m\n",
      "\u001b[34m[22:53:18] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 322 extra nodes, 4 pruned nodes, max_depth=11\u001b[0m\n",
      "\u001b[34m[4]#011train-rmse:8.49231#011validation-rmse:9.58978\u001b[0m\n",
      "\u001b[34m[22:53:18] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 188 extra nodes, 0 pruned nodes, max_depth=11\u001b[0m\n",
      "\u001b[34m[5]#011train-rmse:7.48218#011validation-rmse:8.83035\u001b[0m\n",
      "\u001b[34m[22:53:18] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 288 extra nodes, 4 pruned nodes, max_depth=11\u001b[0m\n",
      "\u001b[34m[6]#011train-rmse:6.74975#011validation-rmse:8.54087\u001b[0m\n",
      "\u001b[34m[22:53:18] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 196 extra nodes, 4 pruned nodes, max_depth=11\u001b[0m\n",
      "\u001b[34m[7]#011train-rmse:6.35884#011validation-rmse:8.43067\u001b[0m\n",
      "Training seconds: 54\n",
      "Billable seconds: 54\n"
     ]
    }
   ],
   "source": [
    "xgb_estimator = sagemaker.estimator.Estimator.attach(xgb_hyperparameter_tuner.best_training_job())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_job_name = xgb_hyperparameter_tuner.best_training_job()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_data = \"s3://{}/{}/output/{}/output/model.tar.gz\".format(bucket, model_prefix, best_job_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed 25.5 KiB/25.5 KiB (391.8 KiB/s) with 1 file(s) remaining\r",
      "download: s3://sagemaker-us-east-2-278383315865/santander_project/XGBoost/output/xgboost-200727-2246-004-85c4a7e8/output/model.tar.gz to models/model.tar.gz\r\n"
     ]
    }
   ],
   "source": [
    "# Saving XGBoost model data to model directory\n",
    "!aws s3 cp $model_data $model_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.rename(os.path.join(model_dir, 'model.tar.gz'), os.path.join(model_dir, 'XGB-model-{}-{}'.format(transform, time)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
