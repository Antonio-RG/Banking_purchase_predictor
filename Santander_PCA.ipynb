{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import preprocessing, decomposition, model_selection\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = 'input_data'\n",
    "seed=0\n",
    "\n",
    "# Reading in training dataset\n",
    "train_df = pd.read_csv(os.path.join(data_dir, 'train.csv'), index_col='ID')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA Reduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, comparing performance of various PCA kernels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaling features to means\n",
    "std_scale = preprocessing.StandardScaler().fit(train_df.iloc[:, 1:])\n",
    "train_df_scaled = std_scale.transform(train_df.iloc[:, 1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying Box-Cox transform to target\n",
    "train_df['target'] = stats.boxcox(train_df['target'])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Looping through kernels and plotting component correlations to target\n",
    "kernels=['linear', 'poly', 'rbf', 'sigmoid', 'cosine']\n",
    "n_components=200\n",
    "\n",
    "fig = plt.figure(figsize=(20, 20))\n",
    "\n",
    "kernel_outputs = {}\n",
    "\n",
    "for i, kernel in enumerate(kernels):\n",
    "    kpca_sm = decomposition.KernelPCA(n_components=n_components, kernel=kernel)\n",
    "    kpca_sm.fit(train_df_scaled)\n",
    "    train_df_kpca = pd.concat([train_df['target'], pd.DataFrame(kpca_sm.transform(train_df_scaled), columns=['c{}'.format(num+1) for num in range(n_components)], index=train_df.index)], axis=1)\n",
    "    correlation_kpca = train_df_kpca.corr(method='spearman')['target'][1:]\n",
    "    \n",
    "    #Saving results in dictionary for post-evaluation use\n",
    "    kernel_outputs[kernel] = {}\n",
    "    kernel_outputs[kernel]['coeffs'] = correlation_kpca\n",
    "    kernel_outputs[kernel]['data']= train_df_kpca\n",
    "    kernel_outputs[kernel]['transformer'] = kpca_sm\n",
    "    \n",
    "    #Plotting results\n",
    "    ax = fig.add_subplot(3, 2, i+1)\n",
    "    ax.scatter(range(len(correlation_kpca)), np.sort(correlation_kpca))\n",
    "    ax.set_title('Component/Target Correlation ({} Kernel)'.format(kernel))\n",
    "    ax.set_xlabel('Components')\n",
    "    ax.set_ylabel('Correlation')\n",
    "    ax.set_ylim(-.3, .3)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The polynomial kernel appears to have the highest magnitude of correlations to the target. Before selecting an option, checking the performance of a sparse PCA method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Instantiating and fitting sparse PCA algorithm\n",
    "sparse_sm = decomposition.SparsePCA(n_components=n_components)\n",
    "sparse_sm.fit(train_df_scaled)\n",
    "train_df_sparse = pd.concat([train_df['target'], pd.DataFrame(sparse_sm.transform(train_df.iloc[:, 1:].values), columns=['c{}'.format(num+1) for num in range(n_components)], index=train_df.index)], axis=1)\n",
    "correlation_sparse = train_df_sparse.corr(method='spearman')['target'][1:]\n",
    "\n",
    "#Saving outputs to earlier created dictionary\n",
    "kernel_outputs['sparse'] = {}\n",
    "kernel_outputs['sparse']['coeffs'] = correlation_sparse\n",
    "kernel_outputs['sparse']['data'] = train_df_sparse\n",
    "kernel_outputs['sparse']['transformer'] = sparse_sm\n",
    "\n",
    "#Plotting output correlation\n",
    "plt.scatter(range(len(correlation_sparse)), np.sort(correlation_sparse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choosing and Applying a PCA Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PCA using a polynomial model appeared to perform the best. Using a gridsearch to optimize the paramaters, assuming this will be ultimately fitted to a gradient boosting regression model. Selecting components meeting correlation threshold and saving to a dataframe for regression modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimizing parameters\n",
    "\n",
    "poly_kpca = decomposition.KernelPCA(n_components=n_components, kernel='poly')\n",
    "\n",
    "GBRegressor = GradientBoostingRegressor()\n",
    "\n",
    "X = train_df_scaled\n",
    "y = train_df['target'] \n",
    "\n",
    "pipe = Pipeline(steps=[('pca', poly_kpca), ('grb_regressor', GBRegressor)])\n",
    "\n",
    "param_grid = {\n",
    "    'pca__gamma': [1, 10, 100, 1000],\n",
    "    'pca__degree': [3, 4, 5],\n",
    "}\n",
    "\n",
    "pca_search = GridSearchCV(pipe, param_grid, n_jobs=-1)\n",
    "pca_search.fit(X, y)\n",
    "\n",
    "pca_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimized_kpca = pca_search.best_estimator_[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting PCA algorithm to data\n",
    "\n",
    "optimized_kpca.fit(train_df_scaled)\n",
    "train_df_optimized = pd.concat([train_df['target'], pd.DataFrame(optimized_kpca.transform(train_df_scaled), columns=['c{}'.format(num+1) for num in range(n_components)], index=train_df.index)], axis=1)\n",
    "correlation_optimized = train_df_optimized.corr(method='spearman')['target'][1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reducing components based on correlation threshold\n",
    "\n",
    "pca_threshold = .1\n",
    "\n",
    "best_components = correlation_optimized[abs(correlation_optimized) >= pca_threshold].sort_values(ascending=False)\n",
    "pca_cols = [['target'] + list(best_components.index)][0]\n",
    "train_df_final_pca = train_df_optimized.loc[:, pca_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Saving component-populated dataframe to local drive\n",
    "train_df_final_pca.to_csv(os.path.join(data_dir, 'train_pca.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Freeing memory\n",
    "train_df_final_pca = None\n",
    "train_df = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transforming test data using fitted standard scaler and PCA model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reading in test data\n",
    "chunksize = 5000\n",
    "test_df_pca = pd.DataFrame()\n",
    "\n",
    "for chunk in pd.read_csv(os.path.join(data_dir, 'test.csv'), index_col='ID', chunksize=chunksize):\n",
    "    test_df_pca = pd.concat([test_df_pca, chunk])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Transforming test data using selected PCA kernel\n",
    "test_df_pca = pd.DataFrame(optimized_kpca.transform(std_scale.transform(test_df_pca.values)), columns=['c{}'.format(num+1) for num in range(n_components)], index=test_df_pca.index).loc[:, list(best_components.index)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df_pca.to_csv(os.path.join(data_dir, 'test_pca.csv'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
